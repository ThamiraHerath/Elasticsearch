---
create logsdb data stream with host.name as keyword:
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host.name:
                  type: "keyword"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      indices.create_data_stream:
        name: "logsdb"

  - is_true: acknowledged

---
create logsdb data stream with host.name as keyword and timestamp as date:
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host.name:
                  type: "keyword"
                "@timestamp":
                  type: "date"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      indices.create_data_stream:
        name: "logsdb"

  - is_true: acknowledged

---
create logsdb data stream with host as keyword:
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host:
                  type: "keyword"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      catch: bad_request
      indices.create_data_stream:
        name: "logsdb"

  - match: { error.type: "mapper_parsing_exception" }
  - match: { error.reason: "Failed to parse mapping: can't merge a non object mapping [host] with an object mapping" }

---
create logsdb data stream with host as text and multi fields:
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host:
                  type: "text"
                  fields:
                    keyword:
                      ignore_above: 256
                      type: "keyword"
                "@timestamp":
                  type: "date"
                  format: "strict_date_optional_time"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      catch: bad_request
      indices.create_data_stream:
        name: "logsdb"

  - match: { error.type: "mapper_parsing_exception" }
  - match: { error.reason: "Failed to parse mapping: can't merge a non object mapping [host] with an object mapping" }

---
create logsdb data stream with host as text:
  - requires:
      cluster_features: ["mapper.keyword_normalizer_synthetic_source"]
      reason: "Support for normalizer on keyword fields"

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host:
                  type: "text"
                "@timestamp":
                  type: "date"
                  format: "strict_date_optional_time"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      catch: bad_request
      indices.create_data_stream:
        name: "logsdb"

  - match: { error.type: "mapper_parsing_exception" }
  - match: { error.reason: "Failed to parse mapping: can't merge a non object mapping [host] with an object mapping" }

---
create logsdb data stream with host as text and name as double:
  - requires:
      cluster_features: ["mapper.keyword_normalizer_synthetic_source"]
      reason: "Support for normalizer on keyword fields"

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host:
                  type: "text"
                  fields:
                    name:
                      type: "double"
                "@timestamp":
                  type: "date"
                  format: "strict_date_optional_time"

  - do:
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - do:
      catch: bad_request
      indices.create_data_stream:
        name: "logsdb"

  - match: { error.type: "mapper_parsing_exception" }
  - match: { error.reason: "Failed to parse mapping: can't merge a non object mapping [host] with an object mapping" }

---
create logsdb data stream with timestamp object mapping:
  - requires:
      cluster_features: ["mapper.keyword_normalizer_synthetic_source"]
      reason: "Support for normalizer on keyword fields"

  - do:
      cluster.put_component_template:
        name: "logsdb-mappings"
        body:
          template:
            settings:
              mode: "logsdb"
            mappings:
              properties:
                host:
                  properties:
                    name:
                      type: "keyword"
                "@timestamp":
                  properties:
                    date:
                      type: "date"
                      format: "strict_date_optional_time"

  - do:
      catch: bad_request
      indices.put_index_template:
        name: "logsdb-index-template"
        body:
          index_patterns: ["logsdb"]
          data_stream: {}
          composed_of: ["logsdb-mappings"]

  - match: { error.type: "illegal_argument_exception" }
  - match: { error.reason: "composable template [logsdb-index-template] template after composition with component templates [logsdb-mappings] is invalid" }

---
create logsdb data stream with custom sorting without host.name:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-http-prod ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ agent.id ]
                sort.order: [ desc ]
                mode: logsdb
            mappings:
              properties:
                agent.id:
                  type: keyword
                host.hostname:
                  type: keyword
          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-http-prod
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-http-prod

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.agent.properties.id.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: null }

---
create logsdb data stream with custom sorting and host object:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-nginx-prod ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ host.hostname, host.region ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    ip:
                      type: ip
                    hostname:
                      type: keyword
                    region:
                      type: keyword
                    name:
                      type: integer

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-nginx-prod
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-nginx-prod

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.ip.type: ip }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.region.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: integer } # Overrides LogsDB injected

---
create logsdb data stream with custom sorting and dynamically mapped host.name:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-kafka-qa ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ "agent.id", "@timestamp" ]
                sort.order: [ desc, asc ]
                mode: logsdb
            mappings:
              properties:
                agent:
                  type: object
                  properties:
                    name:
                      type: keyword
                    id:
                      type: keyword

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-kafka-qa
  - is_true: acknowledged

  - do:
      bulk:
        index: logs-kafka-qa
        refresh: true
        body:
          - { "create": { } }
          - { "@timestamp": "2022-01-01T00:00:00", agent.name: "foo", agent.id: "foo-568", host: { name: "db8fdcf1-b1e2-444b-8c6a-0466c61dcce4", id: 568 } }
          - { "create": { } }
          - { "@timestamp": "2022-01-01T00:01:00", agent.name: "bar", agent.id: "foo-309", host: { name: "35e1ed10-961e-46c7-83ea-4109c913a1d6", id: 309 } }

  - do:
      indices.get_data_stream:
        name: logs-kafka-qa

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.agent.properties.name.type: keyword }
  - match: { .$backing_index.mappings.properties.agent.properties.id.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: text }
  - match: { .$backing_index.mappings.properties.host.properties.id.type: long }
  - match: { .$backing_index.mappings.properties.host.properties.name.ignore_above: null }

---
create logsdb data stream with custom sorting and host.name object:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-nginx-qa ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ "host.name.value", "@timestamp" ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    name:
                      type: object
                      properties:
                        value:
                          type: keyword
                        alias:
                          type: keyword

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-nginx-qa
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-nginx-qa

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.name.properties.value.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.properties.alias.type: keyword }

---
create logsdb data stream with default sorting on malformed host.name:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-win-prod ]
          priority: 10000
          template:
            settings:
              index:
                mode: logsdb
            mappings:
              properties:
                agent:
                  type: object
                  properties:
                    name:
                      type: keyword
                    id:
                      type: keyword

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-win-prod
  - is_true: acknowledged

  - do:
      bulk:
        index: logs-win-prod
        refresh: true
        body:
          - { "create": { } }
          - { "@timestamp": "2022-01-01T00:00:00", agent.name: "foo", agent.id: "foo-568", host: { name: 192.168.10.12, id: "e70e91cd-bb3f-43f0-909c-2748e7fdfd54" } }
          - { "create": { } }
          - { "@timestamp": "2022-01-01T00:01:00", agent.name: "bar", agent.id: "foo-309", host: { name: 192.168.15.17, id: "ad2e3edb-2c4b-4f12-83dd-255691ed614c" } }

  - do:
      indices.get_data_stream:
        name: logs-win-prod

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.agent.properties.name.type: keyword }
  - match: { .$backing_index.mappings.properties.agent.properties.id.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: keyword } # LogsDB injected
  - match: { .$backing_index.mappings.properties.host.properties.name.ignore_above: 1024 } # LogsDB injected
  - match: { .$backing_index.mappings.properties.host.properties.id.type: text }

---
create logsdb data stream with custom sorting and host.name date field:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-http-prod ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ host.name, host.hostname ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    hostname:
                      type: keyword
                    name:
                      type: date

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-http-prod
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-http-prod

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: date }

---
create logsdb data stream with custom sorting and missing host.name field mapping:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-http-qa ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ host.name, host.hostname ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    hostname:
                      type: keyword

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-http-qa
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-http-qa

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.ignore_above: 1024 }

---
create logsdb data stream with custom sorting and host.name date field:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-http-prod ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ host.name, host.hostname ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    hostname:
                      type: keyword
                    name:
                      type: date

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-http-prod
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-http-prod

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: date }

---
create logsdb data stream with custom sorting and host.name field without doc values:
  - skip:
      features: [ "allowed_warnings" ]
  - requires:
      cluster_features: [ "mapper.keyword_normalizer_synthetic_source" ]
      reason: support for normalizer on keyword fields

  - do:
      allowed_warnings:
        - "index template [logs-template] has index patterns [logs-*-*] matching patterns from existing older templates [global] with patterns (global => [*]); this template [logs-template] will take precedence during new index creation"
      indices.put_index_template:
        name: logs-template
        body:
          index_patterns: [ logs-http-dev ]
          priority: 10000
          template:
            settings:
              index:
                sort.field: [ "host.name", "@timestamp" ]
                sort.order: [ desc, desc ]
                mode: logsdb
            mappings:
              properties:
                host:
                  type: object
                  properties:
                    name:
                      type: keyword
                      doc_values: false

          data_stream: { }
  - is_true: acknowledged

  - do:
      indices.create_data_stream:
        name: logs-http-dev
  - is_true: acknowledged

  - do:
      indices.get_data_stream:
        name: logs-http-dev

  - set: { data_streams.0.indices.0.index_name: backing_index }
  - do:
      indices.get_mapping:
        index: $backing_index

  - match: { .$backing_index.mappings.properties.@timestamp.type: date }
  - match: { .$backing_index.mappings.properties.host.properties.hostname.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.type: keyword }
  - match: { .$backing_index.mappings.properties.host.properties.name.ignore_above: 1024 }
